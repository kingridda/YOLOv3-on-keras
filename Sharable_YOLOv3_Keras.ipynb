{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sharable_YOLOv3_PFA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Juyrfn0wQR0x"
      },
      "source": [
        "#Downloading translated to Keras model and wights (original model is implemented on C and Darknet)\n",
        "#https://drive.google.com/file/d/1--xywTuz4928rVzLP7sbBL3lH-xpJR9G/view?usp=sharing\n",
        "\n",
        "!gdown --id 1--xywTuz4928rVzLP7sbBL3lH-xpJR9G\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwIdS-sgWRlA"
      },
      "source": [
        "!unzip YOLOv3.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h3mfVCR1GF2"
      },
      "source": [
        "#uplaoding some test images to the environment\n",
        "#https://drive.google.com/file/d/1A9e2tZ-EP7oLH1FU_KRfE7GXTS3-C40y/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1TbzCbx-dQTxG67duFJHxAwq-sEQyPARm/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1pCjy-GjGowyeE9KWe2_QHh2OMrkHnAMD/view?usp=sharing\n",
        "!gdown --id 1pCjy-GjGowyeE9KWe2_QHh2OMrkHnAMD\n",
        "!gdown --id 1TbzCbx-dQTxG67duFJHxAwq-sEQyPARm\n",
        "!gdown --id 1A9e2tZ-EP7oLH1FU_KRfE7GXTS3-C40y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFXZRa1AXOAZ"
      },
      "source": [
        "#copy the packages and images to the content folder\n",
        "!cp -r 'content/YOLOv3/.' /content\n",
        "!cp test.jpg test2.jpg test3.jpg /content/images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXO-Aopb6Gye"
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "import scipy.io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import PIL\n",
        "from PIL import ImageFont, ImageDraw\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework.ops import EagerTensor\n",
        "import time\n",
        "\n",
        "#model packages\n",
        "from tensorflow.keras.models import load_model\n",
        "from yad2k.models.keras_yolo import yolo_head\n",
        "from yad2k.utils.utils import draw_boxes, get_colors_for_classes, scale_boxes, read_classes, read_anchors, preprocess_image\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRCO4hWY7UwS"
      },
      "source": [
        "# utils\n",
        "\n",
        "#changing box coordinate to corners (easier for processing)\n",
        "def yolo_boxes_to_corners(box_xy, box_wh):\n",
        "    \"\"\"Convert YOLO box predictions to bounding box corners.\"\"\"\n",
        "    box_mins = box_xy - (box_wh / 2.)\n",
        "    box_maxes = box_xy + (box_wh / 2.)\n",
        "\n",
        "    return tf.keras.backend.concatenate([\n",
        "        box_mins[..., 1:2],  # y_min\n",
        "        box_mins[..., 0:1],  # x_min\n",
        "        box_maxes[..., 1:2],  # y_max\n",
        "        box_maxes[..., 0:1]  # x_max\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq3BE5sn6Vl7"
      },
      "source": [
        "#filtering boxes based on score/proba\n",
        "def yolo_filter_boxes(boxes, box_confidence, box_class_probs, threshold = .6):\n",
        "    x = 10\n",
        "    y = tf.constant(100)\n",
        "    # Compute box scores\n",
        "    box_scores = box_confidence * box_class_probs\n",
        "\n",
        "    # Find the box_classes using the max box_scores, keep track of the corresponding score\n",
        "    box_classes      = tf.math.argmax(box_scores, axis=-1)\n",
        "    box_class_scores = tf.math.reduce_max(box_scores, axis=-1, keepdims=False)\n",
        "    \n",
        "    # Create a filtering mask based on \"box_class_scores\" by using \"threshold\"(with probability >= threshold)\n",
        "    filtering_mask = (box_class_scores >= threshold)\n",
        "    \n",
        "    # Applying the mask to box_class_scores, boxes and box_classes\n",
        "    scores = tf.boolean_mask( box_class_scores, filtering_mask)\n",
        "    boxes = tf.boolean_mask( boxes, filtering_mask)\n",
        "    classes = tf.boolean_mask( box_classes, filtering_mask)\n",
        "\n",
        "    return scores, boxes, classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzeuXLtV7Em1"
      },
      "source": [
        "#non max suppression algorithm based on IoU (intersection over union)\n",
        "def yolo_non_max_suppression(scores, boxes, classes, max_boxes = 10, iou_threshold = 0.5):\n",
        "    \n",
        "    max_boxes_tensor = tf.Variable(max_boxes, dtype='int32')     # tensor to be used in tf.image.non_max_suppression()\n",
        "    \n",
        "    # Use tf.image.non_max_suppression() to get the list of indices corresponding to boxes you keep\n",
        "    nms_indices =tf.image.non_max_suppression(boxes, scores, max_boxes, iou_threshold=iou_threshold, score_threshold=float('-inf'))\n",
        "     \n",
        "    #tf.gather() to select only nms_indices from scores, boxes and classes\n",
        "    \n",
        "    scores = tf.gather(scores, nms_indices)\n",
        "    boxes = tf.gather(boxes, nms_indices)\n",
        "    classes = tf.gather(classes, nms_indices)\n",
        "    \n",
        "    return scores, boxes, classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh9d-zaZ7btT"
      },
      "source": [
        "#function that process the raw output of the YOLOv3 model\n",
        "def yolo_eval(yolo_outputs, image_shape = (720, 1280), max_boxes=10, score_threshold=.6, iou_threshold=.5):\n",
        "    \n",
        "    # Retrieve outputs of the YOLO model \n",
        "    box_xy, box_wh, box_confidence, box_class_probs = yolo_outputs\n",
        "\n",
        "    # Convert boxes to be ready for filtering functions\n",
        "    boxes = yolo_boxes_to_corners(box_xy, box_wh)\n",
        "\n",
        "    #Score-filtering with a threshold of score_threshold\n",
        "    scores, boxes, classes = yolo_filter_boxes(boxes, box_confidence, box_class_probs, threshold = score_threshold)\n",
        "    \n",
        "    boxes = scale_boxes(boxes, image_shape)\n",
        "\n",
        "    scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes, max_boxes = max_boxes, iou_threshold = iou_threshold)\n",
        "    \n",
        "    return scores, boxes, classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTf3ay6A7uhC"
      },
      "source": [
        "#loading the model, classes and anchor boxes\n",
        "class_names = read_classes(\"model_data/coco_classes.txt\")\n",
        "anchors = read_anchors(\"model_data/yolo_anchors.txt\")\n",
        "model_image_size = (608, 608)\n",
        "\n",
        "yolo_model = load_model(\"model_data/\", compile=False)\n",
        "yolo_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ugIRJ1m16Nf"
      },
      "source": [
        "#model details\n",
        "yolo_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTk3H_8b8q2a"
      },
      "source": [
        "#predict on the image, process the output, draw the filtred boxes on the image and saving the results to out file\n",
        "def predict(image_file, confidence_threshold ):\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,15))\n",
        "\n",
        "    # Preprocess the image\n",
        "    image, image_data = preprocess_image(\"images/\" + image_file, model_image_size = (608, 608))\n",
        "    axes[0].imshow(image)\n",
        "    yolo_model_outputs = yolo_model(image_data)\n",
        "    yolo_outputs = yolo_head(yolo_model_outputs, anchors, len(class_names))\n",
        "    \n",
        "    out_scores, out_boxes, out_classes = yolo_eval(yolo_outputs, [image.size[1],  image.size[0]], 10, confidence_threshold, 0.5)\n",
        "    # Print predictions info\n",
        "    print('Found {} boxes for {}'.format(len(out_boxes), \"images/\" + image_file))\n",
        "    # Generate colors for drawing bounding boxes.\n",
        "    colors = get_colors_for_classes(len(class_names))\n",
        "    # Draw bounding boxes on the image file\n",
        "    #draw_boxes2(image, out_scores, out_boxes, out_classes, class_names, colors, image_shape)\n",
        "    draw_boxes(image, out_boxes, out_classes, class_names, out_scores)\n",
        "    # Save the predicted bounding box on the image\n",
        "    image.save(os.path.join(\"out\", image_file), quality=100)\n",
        "    plt.figure(2)\n",
        "    axes[1].imshow(image)\n",
        "    # Display the results in the notebook\n",
        "    output_image = PIL.Image.open(os.path.join(\"out\", image_file))\n",
        "\n",
        "    return out_scores, out_boxes, out_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IPUZjsc8uTq"
      },
      "source": [
        "#predicting on a test image (change to other images or upload your own test image)\n",
        "\n",
        "confidence_threshold = .45 #tune this\n",
        "\n",
        "out_scores, out_boxes, out_classes = predict(\"test.jpg\", confidence_threshold)\n",
        "#out_scores, out_boxes, out_classes = predict(\"test2.jpg\", confidence_threshold)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xz1LHY7QZseo"
      },
      "source": [
        "#evaluating inference time\n",
        "#make sure colab runtime is on GPU mode\n",
        "\n",
        "image, input = preprocess_image(\"images/test.jpg\" , model_image_size = (608, 608))\n",
        "\n",
        "T = 0\n",
        "for _ in range(5):\n",
        "    t1 = time.time()\n",
        "    yolo_model(input)\n",
        "    t2 = time.time()\n",
        "    T += (t2-t1)\n",
        "T /= 5\n",
        "print('YOLO inference time : %f s ===> %f FPS' % (T, 1/T)) \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}